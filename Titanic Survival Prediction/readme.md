ğŸš¢ Titanic Survival Prediction â€“ Classification
This project predicts passenger survival on the Titanic using a Random Forest Classifier. The dataset includes demographic and travel information, and demonstrates preprocessing techniques like Label Encoding, missing value handling, and evaluation with classification metrics.

ğŸ›  Tech Stack
Python ğŸ

Pandas (Data Handling)

Scikit-Learn (Preprocessing, Modeling, Evaluation)

ğŸ“‚ Project Structure
 
Titanic_Survival_Prediction/
â”œâ”€â”€ titanic_survival_prediction.py    # Main ML Script
â”œâ”€â”€ titanic.csv                       # Dataset (Passenger Details)
â””â”€â”€ README.md                         # Project Instructions

ğŸ“Š Dataset Example (titanic.csv)

Pclass	Sex	Age	SibSp	Parch	Fare	Survived
3	male	22	1	0	7.25	0
1	female	38	1	0	71.28	1
3	female	26	0	0	7.92	1
...	...	...	...	...	...	...

Survived = 1 â¡ï¸ Passenger Survived

Survived = 0 â¡ï¸ Passenger Did Not Survive

ğŸ“Œ How to Run
Navigate to the Project Folder


cd Titanic_Survival_Prediction
Install Dependencies

 
pip install pandas scikit-learn
Run the Script

 
python titanic_survival_prediction.py

ğŸ§  Project Workflow
âœ… Load the Titanic dataset
âœ… Select relevant columns and handle missing values
âœ… Encode categorical column (Sex) using LabelEncoder
âœ… Define features and target (Survived)
âœ… Split data into training and testing sets
âœ… Train a Random Forest Classifier
âœ… Evaluate with Accuracy & Classification Report

ğŸ”§ Quick Notes
Encoder Type	When to Use	Example Columns
LabelEncoder	For binary categories	Sex, Survived
OneHotEncoder	For 3+ categories (no order)	City, Color

Axis Meaning in Pandas:
Axis	Meaning
axis=0	Operates row-wise
axis=1	Operates column-wise

ğŸ“ˆ Example Output
markdown
 
Accuracy: 0.82
Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.85      0.84        23
           1       0.80      0.78      0.79        18

    accuracy                           0.82        41
   macro avg       0.82      0.82      0.82        41
weighted avg       0.82      0.82      0.82        41

ğŸ¯ Learning Highlights
âœ… Real-world dataset for binary classification
âœ… Handling categorical variables with encoding
âœ… Evaluating models with common classification metrics
âœ… Missing value handling and data cleaning